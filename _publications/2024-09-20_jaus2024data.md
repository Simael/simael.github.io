---
title: "Data Diet: Can Trimming PET/CT Datasets Enhance Lesion Segmentation?"
collection: publications
category: conferences
permalink: /publication/2024-09-20_jaus2024data
excerpt: 'This paper details a data selection strategy for the autoPET3 datacentric track, showing that removing the easiest training samples (based on model loss) reduces false positives—especially in PSMA-PET—and improves both false negative volume and Dice score over the baseline.'
date: 2024-09-20
venue: 'arXiv, MICCAI autoPET III Challenge'
paperurl: 'https://arxiv.org/abs/2409.13548'
bibtexurl: 'http://simael.github.io/files/2024-09-20_jaus2024data.bib'
authors: 'Alexander Jaus, Simon Reiß, Jens Kleesiek, Rainer Stiefelhagen.'
---
In this work, we describe our approach to compete in the autoPET3 datacentric track. While conventional wisdom suggests that larger datasets lead to better model performance, recent studies indicate that excluding certain training samples can enhance model accuracy. We find that in the autoPETIII dataset, a model that is trained on the entire dataset exhibits undesirable characteristics by producing a large number of false positives particularly for PSMA-PETs. We counteract this by removing the easiest samples from the training dataset as measured by the model loss before retraining from scratch. Using the proposed approach we manage to drive down the false negative volume and improve upon the baseline model in both false negative volume and dice score on the preliminary test set. Code and pre-trained models are available at this [http URL](https://github.com/alexanderjaus/autopet3_datadiet).

The method scored 2nd place MICCAI 2024 AutoPET Datacentric Track!