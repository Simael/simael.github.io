---
title: "Bending Reality: Distortion-Aware Transformers for Adapting to Panoramic Semantic Segmentation"
collection: publications
category: conferences
permalink: /publication/2022-06-21_zhang2022bending
excerpt: 'This work tackles the challenge of training panoramic segmentation models using abundant pinhole camera annotations. The proposed Trans4PASS model uses Deformable Patch Embedding and MLP modules to handle panoramic distortions and learns shared semantics via Mutual Prototypical Adaptation for domain alignment. It matches fully supervised results indoors and sets a new state-of-the-art outdoors, reducing the need for many labeled panoramas.'
date: 2022-06-21
venue: 'CVPR'
paperurl: 'https://openaccess.thecvf.com/content/CVPR2022/html/Zhang_Bending_Reality_Distortion-Aware_Transformers_for_Adapting_to_Panoramic_Semantic_Segmentation_CVPR_2022_paper.html'
bibtexurl: 'http://simael.github.io/files/2022-06-21_zhang2022bending.bib'
authors: 'Jiaming Zhang, Kailun Yang, Chaoxiang Ma, Simon Rei√ü, Kunyu Peng, Rainer Stiefelhagen.'
---
 Panoramic images with their 360deg directional view encompass exhaustive information about the surrounding space, providing a rich foundation for scene understanding. To unfold this potential in the form of robust panoramic segmentation models, large quantities of expensive, pixel-wise annotations are crucial for success. Such annotations are available, but predominantly for narrow-angle, pinhole-camera images which, off the shelf, serve as sub-optimal resources for training panoramic models. Distortions and the distinct image-feature distribution in 360deg panoramas impede the transfer from the annotation-rich pinhole domain and therefore come with a big dent in performance. To get around this domain difference and bring together semantic annotations from pinhole- and 360deg surround-visuals, we propose to learn object deformations and panoramic image distortions in the Deformable Patch Embedding (DPE) and Deformable MLP (DMLP) components which blend into our Transformer for PAnoramic Semantic Segmentation (Trans4PASS) model. Finally, we tie together shared semantics in pinhole- and panoramic feature embeddings by generating multi-scale prototype features and aligning them in our Mutual Prototypical Adaptation (MPA) for unsupervised domain adaptation. On the indoor Stanford2D3D dataset, our Trans4PASS with MPA maintains comparable performance to fully-supervised state-of-the-arts, cutting the need for over 1,400 labeled panoramas. On the outdoor DensePASS dataset, we break state-of-the-art by 14.39% mIoU and set the new bar at 56.38%. 