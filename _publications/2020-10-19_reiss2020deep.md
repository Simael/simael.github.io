---
title: "Deep Classification-driven Domain Adaptation for Cross-Modal Driver Behavior Recognition"
collection: publications
category: conferences
permalink: /publication/2020-10-19_reiss2020deep
excerpt: 'We tackle unsupervised domain adaptation for driver activity recognition, where models trained on labeled color images adapt to unlabeled infrared images. Using enhanced Variational Auto-Encoders for image translation with classification-driven optimization, our approach learns a shared latent space, boosting cross-domain recognition by 13.75% over conventional methods.'
date: 2020-10-19
venue: 'IV'
paperurl: 'https://ieeexplore.ieee.org/document/9304782'
bibtexurl: 'http://simael.github.io/files/2020-10-19_reiss2020deep.bib'
authors: 'Simon Rei√ü, Alina Roitberg, Monica Haurilet, Rainer Stiefelhagen.'
---
We encounter a wide range of obstacles when integrating computer vision algorithms into applications inside the vehicle cabin, e.g. variations in illumination, sensor-type and -placement. Thus, designing domain-invariant representations is crucial for employing such models in practice. Still, the vast majority of driver activity recognition algorithms are developed under the assumption of a static domain, i.e. an identical distribution of training- and test data. In this work, we aim to bring driver monitoring to a setting, where domain shifts can occur at any time and explore generative models which learn a shared representation space of the source and target domain. First, we formulate the problem of unsupervised domain adaptation for driver activity recognition, where a model trained on labeled examples from the source domain (i.e. color images) is intended to adjust to a different target domain (i.e. infrared images) where only unlabeled data is available during training. To address this problem, we leverage current progress in image-to-image translation and adopt multiple strategies for learning a joint latent space of the source and target distribution and a mapping function to the domain of interest. As our long-term goal is a robust cross-domain classification, we enhance a Variational Auto-Encoder (VAE) for image translation with a classification-driven optimization strategy. Our model for classification-driven domain transfer leads to the best cross-domain recognition results and outperforms a conventional classification approach in color-to-infrared recognition by 13.75%.